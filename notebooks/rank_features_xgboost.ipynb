{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn import cross_validation\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Required for saving plots\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "training = pd.read_csv(\"./train.csv\", index_col=0)\n",
    "test = pd.read_csv(\"./test.csv\", index_col=0)\n",
    "\n",
    "print(training.shape)\n",
    "print(test.shape)\n",
    "\n",
    "# Replace -999999 in var3 column with most common value 2 \n",
    "training = training.replace(-999999,2)\n",
    "\n",
    "X = training.iloc[:,:-1]\n",
    "y = training.TARGET\n",
    "\n",
    "# Add zeros per row as extra feature\n",
    "# X['n0'] = (X == 0).sum(axis=1)\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import f_classif, chi2\n",
    "from sklearn.preprocessing import Binarizer, scale\n",
    "\n",
    "########################################\n",
    "# Feature Selection\n",
    "########################################\n",
    "\n",
    "# Percentile\n",
    "p = 75\n",
    "\n",
    "# Scale to sample mean and unit variance\n",
    "X_bin = Binarizer().fit_transform(scale(X))\n",
    "\n",
    "# Chi-squared statistics of non-negative feature\n",
    "selectF_classif = SelectPercentile(f_classif, percentile=p).fit(X, y)\n",
    "\n",
    "# ANOVA f-value between label and feature\n",
    "selectChi2 = SelectPercentile(chi2, percentile=p).fit(X_bin, y)\n",
    "\n",
    "# Select features\n",
    "f_classif_selected = selectF_classif.get_support()\n",
    "f_classif_selected_features = [f for i, f in enumerate(X.columns) if f_classif_selected[i]]\n",
    "chi2_selected = selectChi2.get_support()\n",
    "chi2_selected_features = [f for i, f in enumerate(X.columns) if chi2_selected[i]]\n",
    "selected = chi2_selected & f_classif_selected\n",
    "features = [f for f, s in zip(X.columns, selected) if s]\n",
    "X_sel = X[features]\n",
    "\n",
    "print('F_classif selected {} features {}.'.format(f_classif_selected.sum(), \n",
    "       f_classif_selected_features))\n",
    "print('Chi2 selected {} features {}.'.format(chi2_selected.sum(), \n",
    "       chi2_selected_features))\n",
    "print('Chi2 & F_classif selected {} features'.format(selected.sum()))\n",
    "print(features)\n",
    "\n",
    "########################################\n",
    "# Fitting\n",
    "########################################\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X_sel, y, random_state=1301, \n",
    "                                                                     stratify=y, test_size=0.4)\n",
    "\n",
    "ratio = float(np.sum(y == 1)) / np.sum(y==0)\n",
    "\n",
    "clf = xgb.XGBClassifier(missing=9999999999,\n",
    "                        max_depth = 5,\n",
    "                        n_estimators=1000,\n",
    "                        learning_rate=0.1, \n",
    "                        nthread=4,\n",
    "                        subsample=1.0,\n",
    "                        colsample_bytree=0.5,\n",
    "                        min_child_weight = 3,\n",
    "                        scale_pos_weight = ratio,\n",
    "                        reg_alpha=0.03,\n",
    "                        seed=1301)\n",
    "                \n",
    "clf.fit(X_train, y_train, early_stopping_rounds=50, eval_metric=\"auc\",\n",
    "        eval_set=[(X_train, y_train), (X_test, y_test)])\n",
    "        \n",
    "print('Overall AUC:', \n",
    "      roc_auc_score(y, clf.predict_proba(X_sel, ntree_limit=clf.best_iteration)[:,1]))\n",
    "\n",
    "test['n0'] = (test == 0).sum(axis=1)\n",
    "sel_test = test[features]    \n",
    "y_pred = clf.predict_proba(sel_test, ntree_limit=clf.best_iteration)\n",
    "\n",
    "# submission = pd.DataFrame({\"ID\": test.index, \"TARGET\": y_pred[:, 1]})\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "mapFeat = dict(zip([\"f\" + str(i) for i in range(len(features))], features))\n",
    "ts = pd.Series(clf.booster().get_fscore())\n",
    "ts.sort_values()[-15:].plot(kind=\"barh\", title=(\"features importance\"))\n",
    "\n",
    "featp = ts.sort_values()[-15:].plot(kind='barh', x='feature', y='fscore', \n",
    "                                    legend=False, figsize=(6, 10))\n",
    "plt.title('XGBoost Feature Importance')\n",
    "fig_featp = featp.get_figure()\n",
    "fig_featp.savefig('feature_importance_xgb.png', bbox_inches='tight', pad_inches=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
